# ğŸ’¬ chat.llm: Modular C++ LLM Chat Interface for Documents and Beyond

**chat.llm** is a lightweight, extensible C++ desktop application that enables LLM-powered interaction with documents â€” and much more. Chat with your `.pdf` and `.txt` files, generate summaries, translate content, or switch to travel/meal planner mode â€” all through modular system prompts.

Built with [ImGui](https://github.com/ocornut/imgui), [llama.cpp](https://github.com/ggerganov/llama.cpp), [PDFium](https://pdfium.googlesource.com/pdfium), and [utfcpp](https://github.com/nemtrif/utfcpp) for robust Unicode handling.

---

## âœ¨ Key Features

- ğŸ§  **LLM Chat Engine** via `llama.cpp`
- ğŸ“„ **Document Chat**: Interact with `.pdf` and `.txt` files
- ğŸŒ **UTF-8 / Unicode Support**: Reliable multilingual processing using `utfcpp`
- âš™ï¸ **Configurable System Prompts**:
  - ğŸ“š Summarization
  - ğŸŒ Translation (e.g., English â‡Œ Chinese)
  - ğŸ§³ Travel planning
  - ğŸ± Recipe generation
  - ğŸ’¬ General Q&A
- ğŸ§© **Minimalist GUI** using ImGui
- ğŸ’» **Cross-platform** C++17 codebase

---

## ğŸ› ï¸ Example Use Cases

| Mode              | Description                                                |
|-------------------|------------------------------------------------------------|
| Summarizer        | Summarize long PDF/TXT documents in natural language       |
| Translator        | Translate documents between multiple languages             |
| Travel Planner    | Generate trip plans based on user input                    |
| Recipe Assistant  | Plan healthy meals for families or individuals             |
| Freeform Chat     | General assistant/chat mode using your own system prompt   |

Switching between modes is as simple as changing the `system_prompt`.

---

## ğŸ”§ Getting Started

### Requirements

- C++17-compatible compiler
- CMake 3.15+
- llama.cpp-compatible LLM (quantized `.gguf` model)
- PDFium for PDF support

### Build Instructions

```bash
git clone https://github.com/szsteven008/chat.llm.git
cd chat.llm
git submodule update --init --recursive
mkdir build && cd build
cmake ..
make -j
```

## ğŸ“¦ Dependencies
	â€¢	llama.cpp â€” local LLM inference
	â€¢	ImGui â€” GUI framework
	â€¢	PDFium â€” PDF parsing
	â€¢	utfcpp â€” UTF-8 string handling (for Chinese and multilingual support. licensed under Boost Software License 1.0)

## ğŸ–¼ï¸ Screenshot
<img width="964" alt="image" src="https://github.com/user-attachments/assets/1583a720-14e6-4271-ba31-b5c9ce5539ef" />

## ğŸ“„ License
MIT License. 

## â¤ï¸ Credits
â€¢ llama.cpp by Georgi Gerganov
â€¢ Qwen3 by Alibaba Group
â€¢ Dear ImGui by Omar Cornut
â€¢ json by Niels Lohmann
â€¢ utfcpp by Nemanja Trifunovic
